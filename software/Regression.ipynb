{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Retrievals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from numbers import Number\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from plots import retrieval_template, statistical_eval\n",
    "from db_tools import read_csv_profiles, read_csv_mean\n",
    "from optimal_estimation import rgrid, z_hatpro, z_top\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T_train = read_csv_profiles(\"../data/unified/training/T_rasoclim.csv\")\n",
    "T_test = read_csv_profiles(\"../data/unified/test/T_rasoclim.csv\")\n",
    "\n",
    "q_train = np.exp(read_csv_profiles(\"../data/unified/training/lnq_rasoclim.csv\"))\n",
    "q_test = np.exp(read_csv_profiles(\"../data/unified/test/lnq_rasoclim.csv\"))\n",
    "\n",
    "TBmwrtm_train = read_csv_profiles(\"../data/unified/training/TB_mwrtm.csv\")\n",
    "TBmwrtm_test = read_csv_profiles(\"../data/unified/test/TB_mwrtm.csv\")\n",
    "\n",
    "TBigmk_train = read_csv_profiles(\"../data/unified/training/TB_igmk.csv\")\n",
    "\n",
    "cloudy_train = read_csv_profiles(\"../data/unified/training/cloudy_raso.csv\")[\"cloudy\"]\n",
    "cloudy_test = read_csv_profiles(\"../data/unified/test/cloudy_raso.csv\")[\"cloudy\"]\n",
    "\n",
    "psfc_train = read_csv_profiles(\"../data/unified/training/psfc.csv\")\n",
    "psfc_test = read_csv_profiles(\"../data/unified/test/psfc.csv\")\n",
    "\n",
    "Tsfc_train = T_train[\"z=612m\"].rename(\"Tsfc\").to_frame()\n",
    "Tsfc_test = T_test[\"z=612m\"].rename(\"Tsfc\").to_frame()\n",
    "\n",
    "qsfc_train = q_train[\"z=612m\"].rename(\"qsfc\").to_frame()\n",
    "qsfc_test = q_test[\"z=612m\"].rename(\"qsfc\").to_frame()\n",
    "\n",
    "T_cosmo0006 = read_csv_profiles(\"../data/unified/priors/T_cosmo7+00+06_mean.csv\")\n",
    "T_cosmo2430 = read_csv_profiles(\"../data/unified/priors/T_cosmo7+24+30_mean.csv\")\n",
    "\n",
    "q_cosmo0006 = np.exp(read_csv_profiles(\"../data/unified/priors/lnq_cosmo7+00+06_mean.csv\"))\n",
    "q_cosmo2430 = np.exp(read_csv_profiles(\"../data/unified/priors/lnq_cosmo7+24+30_mean.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kband_all = [col for col in TBmwrtm_train.columns if \"TB\" in col and int(col[3:8]) < 40000]\n",
    "vband_all = [col for col in TBmwrtm_train.columns if \"TB\" in col and int(col[3:8]) > 40000]\n",
    "vband_zen = [col for col in TBmwrtm_train.columns if \"TB\" in col and int(col[3:8]) > 40000 and col.endswith(\"_00.0\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def join(*dfs, noise=None):\n",
    "    if noise is not None:\n",
    "        if isinstance(noise, Number): noise = [noise]*len(dfs)\n",
    "        dfs = [df + np.random.normal(0., scale=n, size=df.shape) for df, n in zip(dfs, noise)]\n",
    "    return pd.concat(dfs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To detect overfitting and make the synthetic retrievals more 'realistic', Gaussian noise is added to the test data fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TBnoise = 0.5\n",
    "qnoise = 0.0005\n",
    "Tnoise = 0.1\n",
    "pnoise = 0.2\n",
    "\n",
    "TBkqp_train = join(TBmwrtm_train[kband_all], qsfc_train, psfc_train)\n",
    "TBkqp_test = join(TBmwrtm_test[kband_all], qsfc_test, psfc_test, noise=[TBnoise, qnoise, pnoise])\n",
    "\n",
    "TBvTp_train = join(TBmwrtm_train[vband_all], Tsfc_train, psfc_train)\n",
    "TBvTp_test = join(TBmwrtm_test[vband_all], Tsfc_test, psfc_test, noise=[TBnoise, Tnoise, pnoise])\n",
    "\n",
    "TBvzTp_train = join(TBmwrtm_train[vband_zen], Tsfc_train, psfc_train)\n",
    "TBvzTp_test = join(TBmwrtm_test[vband_zen], Tsfc_test, psfc_test, noise=[TBnoise, Tnoise, pnoise])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "    def __init__(self, training_predictors, training_targets, alpha):\n",
    "        self.lm = Ridge(alpha=alpha)\n",
    "        self.lm.fit(training_predictors, training_targets)\n",
    "        self.predictor_cols = list(training_predictors.columns)\n",
    "        self.target_cols = list(training_targets.columns)\n",
    "    \n",
    "    def __call__(self, test_predictors):\n",
    "        assert list(test_predictors.columns) == self.predictor_cols\n",
    "        prediction = self.lm.predict(test_predictors.values)\n",
    "        return pd.DataFrame(prediction, index=test_predictors.index, columns=self.target_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choice of Regularization Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "alphas = [50, 200, 500, 1000, 4000]\n",
    "\n",
    "regTs = [Model(TBvTp_train, T_train, alpha=alpha) for alpha in alphas]\n",
    "statistical_eval(ax1, T_test, *[m(TBvTp_test) for m in regTs], labels=[\"α = {}\".format(alpha) for alpha in alphas])\n",
    "ax1.legend(loc=\"upper right\")\n",
    "ax1.set_ylim(0, 7)\n",
    "ax1.set_xlim(-0.4, 2.5)\n",
    "ax1.grid()\n",
    "\n",
    "regqs = [Model(TBkqp_train, q_train, alpha=alpha) for alpha in alphas]\n",
    "statistical_eval(ax2, q_test, *[m(TBkqp_test) for m in regqs], labels=[\"α = {}\".format(alpha) for alpha in alphas])\n",
    "ax2.legend(loc=\"upper right\")\n",
    "ax2.set_ylim(0, 7)\n",
    "ax2.set_xlim(-0.00015, 0.0012)\n",
    "ax2.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that a regularization parameter of 500 is a good choice.\n",
    "\n",
    "## Default Retrievals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regT_all = Model(TBvTp_train, T_train, alpha=500)\n",
    "regT_zen = Model(TBvzTp_train, T_train, alpha=500)\n",
    "regq = Model(TBkqp_train, q_train, alpha=500)\n",
    "# See next section for clear sky retrievals\n",
    "regq_clear = Model(TBkqp_train.loc[~cloudy_train,:], q_train.loc[~cloudy_train,:], alpha=500)\n",
    "\n",
    "fig, (axT1, axT2, axq1, axq2) = retrieval_template([8, 7],\n",
    "        Tlims=[(-0.5, 4.5), (0, 12), (-0.3, 1.5), (0, 2.5)],\n",
    "        qlims=[(-0.15, 1), (0, 12), (-0.15, 1), (0, 2.5)]\n",
    "        )\n",
    "\n",
    "for ax in [axT1, axT2]:\n",
    "    statistical_eval(ax, T_test,\n",
    "         regT_zen(TBvzTp_test),\n",
    "         regT_all(TBvTp_test),\n",
    "         labels=[\"zenith only\", \"elevation scan\"],\n",
    "         colors=[\"#000000\", \"#33a02c\"])\n",
    "axT2.set_xticks([0.2*i for i in range(-1, 8)])\n",
    "    \n",
    "for ax in [axq1, axq2]:\n",
    "    statistical_eval(ax, q_test*1000,\n",
    "         regq(TBkqp_test)*1000,\n",
    "         regq_clear(TBkqp_test.loc[~cloudy_test,:])*1000,\n",
    "         labels=[\"all sky training/test\", \"clear sky training/test\"],\n",
    "         colors=[\"#000000\", \"#1f78b4\"])\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "axT1.set_title(\"statistical model evaluation\", loc=\"left\", size=11)\n",
    "axq1.set_title(\"bias (dashed) and rmse (solid)\", loc=\"right\", size=11)\n",
    "axT1.legend(loc=\"upper right\", fontsize=11)\n",
    "axq1.legend(loc=\"upper right\", fontsize=11)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../tex/figures/retrieval_regression.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the all-sky regression results for use in the case studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regT_all(TBvTp_test).to_csv(\"../data/unified/retrievals/T_regression.csv\")\n",
    "np.log(regq(TBkqp_test)).to_csv(\"../data/unified/retrievals/lnq_regression.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear Sky Only Retrievals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regT_clear = Model(TBvTp_train.loc[~cloudy_train,:], T_train.loc[~cloudy_train,:], alpha=500)\n",
    "regT_all = Model(TBvTp_train, T_train, alpha=500)\n",
    "regq_clear = Model(TBkqp_train.loc[~cloudy_train,:], q_train.loc[~cloudy_train,:], alpha=500)\n",
    "regq_all = Model(TBkqp_train, q_train, alpha=500)\n",
    "\n",
    "fig, (axT1, axT2, axq1, axq2) = retrieval_template([8, 7],\n",
    "        Tlims=[(-0.5, 4.5), (0, 12), (-0.35, 1.5), (0, 2.5)],\n",
    "        qlims=[(-0.15, 1), (0, 12), (-0.15, 1), (0, 2.5)],                                                  \n",
    "        )\n",
    "\n",
    "for ax in [axT1, axT2]:\n",
    "    statistical_eval(ax, T_test,\n",
    "         regT_all(TBvTp_test.loc[~cloudy_test,:]),\n",
    "         regT_clear(TBvTp_test.loc[~cloudy_test,:]),\n",
    "         labels=[\"all sky training\", \"clear sky training\"],\n",
    "         colors=[\"#000000\", \"#33a02c\"])\n",
    "axT2.set_xticks([0.2*i for i in range(-1, 8)])\n",
    "    \n",
    "for ax in [axq1, axq2]:\n",
    "    statistical_eval(ax, q_test*1000,\n",
    "         regq_all(TBkqp_test.loc[~cloudy_test,:])*1000,\n",
    "         regq_clear(TBkqp_test.loc[~cloudy_test,:])*1000,\n",
    "         labels=[\"all sky training\", \"clear sky training\"],\n",
    "         colors=[\"#000000\", \"#33a02c\"])\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "axT1.legend(loc=\"upper right\", fontsize=11)\n",
    "axq1.legend(loc=\"upper right\", fontsize=11)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature is not affected, to save space only the clear sky retrieval for humidity will be shown in the thesis and has been integrated into the previous plot.\n",
    "\n",
    "## Retrievals with COSMO-7 data as additional predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosmo_data(predictors, cosmo):\n",
    "    data_all = join(predictors, cosmo).dropna()\n",
    "    test = data_all.iloc[::3,:]\n",
    "    train = data_all.drop(test.index, axis=0)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T0006_train, T0006_test = cosmo_data(TBvTp_test, T_cosmo0006.iloc[:,20::4])\n",
    "T2430_train, T2430_test = cosmo_data(TBvTp_test, T_cosmo2430.iloc[:,20::4])\n",
    "\n",
    "q0006_train, q0006_test = cosmo_data(TBkqp_test, q_cosmo0006.iloc[:,:20:4])\n",
    "q2430_train, q2430_test = cosmo_data(TBkqp_test, q_cosmo2430.iloc[:,:20:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T0006_test.columns[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regT_def = Model(TBvTp_train, T_train, alpha=500)\n",
    "regT0006 = Model(T0006_train, T_test.loc[T0006_train.index,:], alpha=500)\n",
    "regT2430 = Model(T2430_train, T_test.loc[T2430_train.index,:], alpha=500)\n",
    "\n",
    "regq_def = Model(TBkqp_train, q_train, alpha=500)\n",
    "regq0006 = Model(q0006_train, q_test.loc[q0006_train.index,:], alpha=500)\n",
    "regq2430 = Model(q2430_train, q_test.loc[q2430_train.index,:], alpha=500)\n",
    "\n",
    "fig, (axT, axq) = plt.subplots(1, 2, figsize=[8, 4.2])\n",
    "\n",
    "statistical_eval(axT, T_test,\n",
    "         regT0006(T0006_test),\n",
    "         regT_def(TBvTp_test),\n",
    "         #regT2430(T2430_test),\n",
    "         labels=[\"COSMO-7\", \"default\", \"2430\"],\n",
    "         colors=[\"#000000\", \"#33a02c\", \"#666666\"])\n",
    "    \n",
    "statistical_eval(axq, q_test*1000,\n",
    "         regq0006(q0006_test)*1000,\n",
    "         regq_def(TBkqp_test)*1000,\n",
    "         #regq2430(q2430_test)*1000,\n",
    "         labels=[\"COSMO-7 data included\", \"COSMO-7 data not included\"],\n",
    "         colors=[\"#000000\", \"#33a02c\", \"#666666\"])\n",
    "\n",
    "axT.set_title(\"statistical model evaluation\", loc=\"left\", size=11)\n",
    "axq.set_title(\"bias (dashed) and rmse (solid)\", loc=\"right\", size=11)\n",
    "axT.set_xlim(-0.5, 4.5)\n",
    "axT.set_ylim(0, 12)\n",
    "axT.set_xlabel(\"temperature [K]\")\n",
    "axq.set_xlim(-0.15, 1)\n",
    "axq.set_ylim(0, 12)\n",
    "axq.set_xlabel(\"total water content [g/kg]\")\n",
    "axq.set_ylabel(\"\")\n",
    "axq.legend(loc=\"upper right\", fontsize=11)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../tex/figures/retrieval_regression_cosmo.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Reduced bias partially due to bias removal of COSMO-7 data.\n",
    "\n",
    "## Application to actual HATPRO measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TB_bias = read_csv_mean(\"../data/unified/priors/TB_mwrtm_bias.csv\")\n",
    "TB_hatpro = read_csv_profiles(\"../data/unified/test/TB_hatpro.csv\")\n",
    "# Bias is model - HATPRO therefore has to be added to the HATPRO observations\n",
    "TB_hatpro_nobias = TB_hatpro + TB_bias\n",
    "sfc_hatpro = read_csv_profiles(\"../data/unified/test/sfc_hatpro.csv\")\n",
    "\n",
    "TB_hatpro = TB_hatpro.reindex(T_test.index, method=\"nearest\", tolerance=dt.timedelta(minutes=30)).dropna()\n",
    "TB_hatpro_nobias = TB_hatpro_nobias.reindex(T_test.index, method=\"nearest\", tolerance=dt.timedelta(minutes=30)).dropna()\n",
    "sfc_hatpro = sfc_hatpro.reindex(T_test.index, method=\"nearest\", tolerance=dt.timedelta(minutes=30)).dropna()\n",
    "sfc_hatpro = pd.concat([sfc_hatpro, cloudy_test], axis=1, join=\"inner\")\n",
    "sfc_hatpro.columns = [x if x not in [\"T\", \"qvap\"] else x.replace(\"vap\", \"\")+\"sfc\" for x in sfc_hatpro.columns]\n",
    "\n",
    "TBvTp_hatpro = pd.concat([TB_hatpro.loc[sfc_hatpro[\"rain\"]==0,vband_all], sfc_hatpro[[\"Tsfc\", \"p\"]]], axis=1, join=\"inner\")\n",
    "TBkqp_hatpro = pd.concat([TB_hatpro.loc[sfc_hatpro[\"rain\"]==0,kband_all], sfc_hatpro[[\"qsfc\", \"p\"]]], axis=1, join=\"inner\")\n",
    "TBvTp_hatpro_nobias = pd.concat([TB_hatpro_nobias.loc[sfc_hatpro[\"rain\"]==0,vband_all], sfc_hatpro[[\"Tsfc\", \"p\"]]], axis=1, join=\"inner\")\n",
    "TBkqp_hatpro_nobias = pd.concat([TB_hatpro_nobias.loc[sfc_hatpro[\"rain\"]==0,kband_all], sfc_hatpro[[\"qsfc\", \"p\"]]], axis=1, join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regT_all = Model(TBvTp_train, T_train, alpha=500)\n",
    "regq_all = Model(TBkqp_train, q_train, alpha=500)\n",
    "\n",
    "fig, (axT1, axT2, axq1, axq2) = retrieval_template([8, 7],\n",
    "        Tlims=[(-1, 4), (0, 12), (-0.8, 1.4), (0, 2.5)],\n",
    "        qlims=[(-0.5, 1.3), (0, 12), (-0.1, 1.2), (0, 2.5)],                                                  \n",
    "        )\n",
    "\n",
    "for ax in [axT1, axT2]:\n",
    "    statistical_eval(ax, T_test,\n",
    "         regT_all(TBvTp_hatpro),\n",
    "         regT_all(TBvTp_hatpro_nobias),\n",
    "         regT_all(TBvTp_test.ix[TBvTp_hatpro.index,:]),\n",
    "         labels=[\"HATPRO biased\", \"HATPRO\", \"MWRTM\"],\n",
    "         colors=[\"#666666\", \"#000000\", \"#33a02c\"])\n",
    "    \n",
    "for ax in [axq1, axq2]:\n",
    "    statistical_eval(ax, q_test*1000,\n",
    "         regq_all(TBkqp_hatpro)*1000,\n",
    "         regq_all(TBkqp_hatpro_nobias)*1000,\n",
    "         regq_all(TBkqp_test.ix[TBkqp_hatpro.index,:])*1000,\n",
    "         labels=[\"HATPRO biased\", \"HATPRO\", \"MWRTM\"],\n",
    "         colors=[\"#666666\", \"#000000\", \"#33a02c\"])\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "axq1.legend(loc=\"upper right\", fontsize=11)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../tex/figures/retrieval_regression_hatpro.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
