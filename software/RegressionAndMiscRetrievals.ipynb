{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression and Miscellaneous Retrievals\n",
    "\n",
    "Statistical comparison and a case study with actual radiometer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from numbers import Number\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from plots import retrieval_template, statistical_eval\n",
    "from db_tools import read_csv_profiles, read_csv_mean\n",
    "from optimal_estimation import rgrid, z_hatpro, z_top\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T_train = read_csv_profiles(\"../data/unified/training/T_rasoclim.csv\")\n",
    "T_test = read_csv_profiles(\"../data/unified/test/T_rasoclim.csv\")\n",
    "\n",
    "q_train = np.exp(read_csv_profiles(\"../data/unified/training/lnq_rasoclim.csv\"))\n",
    "q_test = np.exp(read_csv_profiles(\"../data/unified/test/lnq_rasoclim.csv\"))\n",
    "\n",
    "TBmwrtm_train = read_csv_profiles(\"../data/unified/training/TB_mwrtm.csv\")\n",
    "TBmwrtm_test = read_csv_profiles(\"../data/unified/test/TB_mwrtm.csv\")\n",
    "\n",
    "TBigmk_train = read_csv_profiles(\"../data/unified/training/TB_igmk.csv\")\n",
    "\n",
    "cloudy_train = read_csv_profiles(\"../data/unified/training/cloudy_raso.csv\")[\"cloudy\"]\n",
    "cloudy_test = read_csv_profiles(\"../data/unified/test/cloudy_raso.csv\")[\"cloudy\"]\n",
    "\n",
    "psfc_train = read_csv_profiles(\"../data/unified/training/psfc.csv\")\n",
    "psfc_test = read_csv_profiles(\"../data/unified/test/psfc.csv\")\n",
    "\n",
    "Tsfc_train = T_train[\"z=612m\"].rename(\"Tsfc\").to_frame()\n",
    "Tsfc_test = T_test[\"z=612m\"].rename(\"Tsfc\").to_frame()\n",
    "\n",
    "qsfc_train = q_train[\"z=612m\"].rename(\"qsfc\").to_frame()\n",
    "qsfc_test = q_test[\"z=612m\"].rename(\"qsfc\").to_frame()\n",
    "\n",
    "T_cosmo0006 = read_csv_profiles(\"../data/unified/priors/T_cosmo7+00+06_mean.csv\")\n",
    "T_cosmo2430 = read_csv_profiles(\"../data/unified/priors/T_cosmo7+24+30_mean.csv\")\n",
    "\n",
    "q_cosmo0006 = np.exp(read_csv_profiles(\"../data/unified/priors/lnq_cosmo7+00+06_mean.csv\"))\n",
    "q_cosmo2430 = np.exp(read_csv_profiles(\"../data/unified/priors/lnq_cosmo7+24+30_mean.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kband_all = [col for col in TBmwrtm_train.columns if \"TB\" in col and int(col[3:8]) < 40000]\n",
    "vband_all = [col for col in TBmwrtm_train.columns if \"TB\" in col and int(col[3:8]) > 40000]\n",
    "vband_zen = [col for col in TBmwrtm_train.columns if \"TB\" in col and int(col[3:8]) > 40000 and col.endswith(\"_00.0\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def join(*dfs, noise=None):\n",
    "    if noise is not None:\n",
    "        if isinstance(noise, Number): noise = [noise]*len(dfs)\n",
    "        dfs = [df + np.random.normal(0., scale=n, size=df.shape) for df, n in zip(dfs, noise)]\n",
    "    return pd.concat(dfs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To detect overfitting and make the synthetic retrievals more 'realistic', Gaussian noise is added to the test data fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TBnoise = 0.5\n",
    "qnoise = 0.0005\n",
    "Tnoise = 0.1\n",
    "pnoise = 0.2\n",
    "\n",
    "TBkqp_train = join(TBmwrtm_train[kband_all], qsfc_train, psfc_train)\n",
    "TBkqp_test = join(TBmwrtm_test[kband_all], qsfc_test, psfc_test, noise=[TBnoise, qnoise, pnoise])\n",
    "\n",
    "TBvTp_train = join(TBmwrtm_train[vband_all], Tsfc_train, psfc_train)\n",
    "TBvTp_test = join(TBmwrtm_test[vband_all], Tsfc_test, psfc_test, noise=[TBnoise, Tnoise, pnoise])\n",
    "\n",
    "TBvzTp_train = join(TBmwrtm_train[vband_zen], Tsfc_train, psfc_train)\n",
    "TBvzTp_test = join(TBmwrtm_test[vband_zen], Tsfc_test, psfc_test, noise=[TBnoise, Tnoise, pnoise])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "    def __init__(self, training_predictors, training_targets, alpha):\n",
    "        self.lm = Ridge(alpha=alpha)\n",
    "        self.lm.fit(training_predictors, training_targets)\n",
    "        self.predictor_cols = list(training_predictors.columns)\n",
    "        self.target_cols = list(training_targets.columns)\n",
    "    \n",
    "    def __call__(self, test_predictors):\n",
    "        assert list(test_predictors.columns) == self.predictor_cols\n",
    "        prediction = self.lm.predict(test_predictors.values)\n",
    "        return pd.DataFrame(prediction, index=test_predictors.index, columns=self.target_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choice of Regularization Parameter\n",
    "\n",
    "Find the parameter that optimizes regression retrieval performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "alphas = [50, 200, 500, 1000, 4000]\n",
    "\n",
    "regTs = [Model(TBvTp_train, T_train, alpha=alpha) for alpha in alphas]\n",
    "statistical_eval(ax1, T_test, *[m(TBvTp_test) for m in regTs], labels=[\"α = {}\".format(alpha) for alpha in alphas])\n",
    "ax1.legend(loc=\"upper right\")\n",
    "ax1.set_ylim(0, 7)\n",
    "ax1.set_xlim(-0.4, 2.5)\n",
    "ax1.grid()\n",
    "\n",
    "regqs = [Model(TBkqp_train, q_train, alpha=alpha) for alpha in alphas]\n",
    "statistical_eval(ax2, q_test, *[m(TBkqp_test) for m in regqs], labels=[\"α = {}\".format(alpha) for alpha in alphas])\n",
    "ax2.legend(loc=\"upper right\")\n",
    "ax2.set_ylim(0, 7)\n",
    "ax2.set_xlim(-0.00015, 0.0012)\n",
    "ax2.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that a regularization parameter of 500 is a good choice.\n",
    "\n",
    "## Default Retrievals\n",
    "\n",
    "Statistical evalutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regT_all = Model(TBvTp_train, T_train, alpha=500)\n",
    "regT_zen = Model(TBvzTp_train, T_train, alpha=500)\n",
    "regq = Model(TBkqp_train, q_train, alpha=500)\n",
    "# See next section for clear sky retrievals\n",
    "regq_clear = Model(TBkqp_train.loc[~cloudy_train,:], q_train.loc[~cloudy_train,:], alpha=500)\n",
    "\n",
    "fig, (axT1, axT2, axq1, axq2) = retrieval_template([8, 7],\n",
    "        Tlims=[(-0.5, 4.5), (0, 12), (-0.3, 1.5), (0, 2.5)],\n",
    "        qlims=[(-0.15, 1), (0, 12), (-0.15, 1), (0, 2.5)]\n",
    "        )\n",
    "\n",
    "for ax in [axT1, axT2]:\n",
    "    statistical_eval(ax, T_test,\n",
    "         regT_zen(TBvzTp_test),\n",
    "         regT_all(TBvTp_test),\n",
    "         labels=[\"zenith only\", \"elevation scan\"],\n",
    "         colors=[\"#000000\", \"#33a02c\"])\n",
    "axT2.set_xticks([0.2*i for i in range(-1, 8)])\n",
    "    \n",
    "for ax in [axq1, axq2]:\n",
    "    statistical_eval(ax, q_test*1000,\n",
    "         regq(TBkqp_test)*1000,\n",
    "         regq_clear(TBkqp_test.loc[~cloudy_test,:])*1000,\n",
    "         labels=[\"all sky training/test\", \"clear sky training/test\"],\n",
    "         colors=[\"#000000\", \"#1f78b4\"])\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "axT1.set_title(\"statistical retrieval evaluation\", loc=\"left\", size=11)\n",
    "axq1.set_title(\"bias (dashed) and std (solid)\", loc=\"right\", size=11)\n",
    "axT1.legend(loc=\"upper right\", fontsize=11)\n",
    "axq1.legend(loc=\"upper right\", fontsize=11)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../tex/figures/retrieval_regression.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the all-sky regression results for use in the case studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regT_all(TBvTp_test).to_csv(\"../data/unified/retrievals/T_regression.csv\")\n",
    "np.log(regq(TBkqp_test)).to_csv(\"../data/unified/retrievals/lnq_regression.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear Sky Only Retrievals\n",
    "\n",
    "How do clouds affect the retrieval performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regT_clear = Model(TBvTp_train.loc[~cloudy_train,:], T_train.loc[~cloudy_train,:], alpha=500)\n",
    "regT_all = Model(TBvTp_train, T_train, alpha=500)\n",
    "regq_clear = Model(TBkqp_train.loc[~cloudy_train,:], q_train.loc[~cloudy_train,:], alpha=500)\n",
    "regq_all = Model(TBkqp_train, q_train, alpha=500)\n",
    "\n",
    "fig, (axT1, axT2, axq1, axq2) = retrieval_template([8, 7],\n",
    "        Tlims=[(-0.5, 4.5), (0, 12), (-0.35, 1.5), (0, 2.5)],\n",
    "        qlims=[(-0.15, 1), (0, 12), (-0.15, 1), (0, 2.5)],                                                  \n",
    "        )\n",
    "\n",
    "for ax in [axT1, axT2]:\n",
    "    statistical_eval(ax, T_test,\n",
    "         regT_all(TBvTp_test.loc[~cloudy_test,:]),\n",
    "         regT_clear(TBvTp_test.loc[~cloudy_test,:]),\n",
    "         labels=[\"all sky training\", \"clear sky training\"],\n",
    "         colors=[\"#000000\", \"#33a02c\"])\n",
    "axT2.set_xticks([0.2*i for i in range(-1, 8)])\n",
    "    \n",
    "for ax in [axq1, axq2]:\n",
    "    statistical_eval(ax, q_test*1000,\n",
    "         regq_all(TBkqp_test.loc[~cloudy_test,:])*1000,\n",
    "         regq_clear(TBkqp_test.loc[~cloudy_test,:])*1000,\n",
    "         labels=[\"all sky training\", \"clear sky training\"],\n",
    "         colors=[\"#000000\", \"#33a02c\"])\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "axT1.legend(loc=\"upper right\", fontsize=11)\n",
    "axq1.legend(loc=\"upper right\", fontsize=11)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature is not affected, to save space only the clear sky retrieval for humidity will be shown in the thesis and has been integrated into the previous plot.\n",
    "\n",
    "## Combined Approaches\n",
    "\n",
    "Compare:\n",
    "\n",
    "- Regression with COSMO-7 regressors\n",
    "- Optimal estimation with COSMO-7 prior and regression first guess\n",
    "- Optimal estimation with regression prior and COSMO-7 first guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_x(x):\n",
    "    T = x.iloc[:,:50]\n",
    "    T.columns = [col[2:] for col in T.columns]\n",
    "    q = np.exp(x.iloc[:,50:])\n",
    "    q.columns = [col[4:] for col in q.columns]\n",
    "    return T, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# naming order: ..._prior_guess_...\n",
    "conv_cr = read_csv_profiles(\"../data/unified/retrievals/convergence_cosmo_regression_full.csv\")\n",
    "x_cr = read_csv_profiles(\"../data/unified/retrievals/x_cosmo_regression_full.csv\")\n",
    "T_cr, q_cr = split_x(x_cr)\n",
    "\n",
    "conv_rc = read_csv_profiles(\"../data/unified/retrievals/convergence_regression_cosmo_full.csv\")\n",
    "x_rc = read_csv_profiles(\"../data/unified/retrievals/x_regression_cosmo_full.csv\")\n",
    "T_rc, q_rc = split_x(x_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_rc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_cr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosmo_data(predictors, cosmo, offset=0):\n",
    "    data_all = join(predictors, cosmo).dropna()\n",
    "    test = data_all.iloc[offset::4,:]\n",
    "    train = data_all.drop(test.index, axis=0)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation due to few data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T_reg, q_reg = None, None\n",
    "for offset in [0, 1, 2, 3]:\n",
    "    T0006_train, T0006_test = cosmo_data(TBvTp_test, T_cosmo0006.iloc[:,20::4], offset=offset)\n",
    "    q0006_train, q0006_test = cosmo_data(TBkqp_test, q_cosmo0006.iloc[:,:20:4], offset=offset)\n",
    "    regT0006 = Model(T0006_train, T_test.loc[T0006_train.index,:], alpha=500)\n",
    "    regq0006 = Model(q0006_train, q_test.loc[q0006_train.index,:], alpha=500)\n",
    "    if T_reg is None: T_reg = regT0006(T0006_test)\n",
    "    else: T_reg = pd.concat([T_reg, regT0006(T0006_test)], axis=0)\n",
    "    if q_reg is None: q_reg = regq0006(q0006_test)\n",
    "    else: q_reg = pd.concat([q_reg, regq0006(q0006_test)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"   \".join(T0006_test.columns[-9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"   \".join(q0006_test.columns[-9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, (axT1, axT2, axq1, axq2) = retrieval_template([8, 7],\n",
    "        Tlims=[(-0.5, 3.5), (0, 12), (-0.35, 1.3), (0, 2.5)],\n",
    "        qlims=[(-0.22, 1.05), (0, 12), (-0.22, 1.05), (0, 2.5)],                                                  \n",
    "        )\n",
    "\n",
    "for ax in [axT1, axT2]:\n",
    "    statistical_eval(ax, T_test,\n",
    "         T_reg,\n",
    "         T_cr.loc[conv_cr[\"converged\"] == 1,:],\n",
    "         T_rc.loc[conv_rc[\"converged\"] == 1,:],\n",
    "         labels=[\"regression w/ COSMO-7\", \"C-7 prior, reg. guess\", \"reg. prior, C-7 guess\"],\n",
    "         colors=[\"#33a02c\", \"#000000\", \"#666666\"])\n",
    "axT2.set_xticks([0.2*i for i in range(-1, 7)])\n",
    "    \n",
    "for ax in [axq1, axq2]:\n",
    "    statistical_eval(ax, q_test*1000,\n",
    "         q_reg*1000,\n",
    "         q_cr.loc[conv_cr[\"converged\"] == 1,:]*1000,\n",
    "         q_rc.loc[conv_rc[\"converged\"] == 1,:]*1000,\n",
    "         labels=[\"regression with C-7\", \"C-7 prior, reg. guess\", \"reg. prior, C-7 guess\"],\n",
    "         colors=[\"#33a02c\", \"#000000\", \"#666666\"])\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "#axT1.legend(loc=\"upper right\", fontsize=11)\n",
    "axq1.legend(loc=\"upper right\", fontsize=11)\n",
    "fig.tight_layout()\n",
    "\n",
    "axT1.set_title(\"statistical retrieval evaluation\", loc=\"left\", size=11)\n",
    "axq1.set_title(\"bias (dashed) and std (solid)\", loc=\"right\", size=11)\n",
    "axq1.legend(loc=\"upper right\", fontsize=11)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../tex/figures/retrieval_combined.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Reduced bias partially due to bias removal of COSMO-7 data.\n",
    "\n",
    "## Application to actual HATPRO measurements\n",
    "\n",
    "### Statistical comparison\n",
    "\n",
    "Uses only measurements from radiosonde launch times and COSMO-7 priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TB_bias = read_csv_mean(\"../data/unified/priors/TB_mwrtm_bias.csv\")\n",
    "TB_hatpro = read_csv_profiles(\"../data/unified/test/TB_hatpro.csv\")\n",
    "# Bias is model - HATPRO therefore has to be added to the HATPRO observations\n",
    "TB_hatpro_nobias = TB_hatpro + TB_bias\n",
    "sfc_hatpro = read_csv_profiles(\"../data/unified/test/sfc_hatpro.csv\")\n",
    "\n",
    "TB_hatpro = TB_hatpro.reindex(T_test.index, method=\"nearest\", tolerance=dt.timedelta(minutes=30)).dropna()\n",
    "TB_hatpro_nobias = TB_hatpro_nobias.reindex(T_test.index, method=\"nearest\", tolerance=dt.timedelta(minutes=30)).dropna()\n",
    "sfc_hatpro = sfc_hatpro.reindex(T_test.index, method=\"nearest\", tolerance=dt.timedelta(minutes=30)).dropna()\n",
    "sfc_hatpro = pd.concat([sfc_hatpro, cloudy_test], axis=1, join=\"inner\")\n",
    "sfc_hatpro.columns = [x if x not in [\"T\", \"qvap\"] else x.replace(\"vap\", \"\")+\"sfc\" for x in sfc_hatpro.columns]\n",
    "\n",
    "TBvTp_hatpro = pd.concat([TB_hatpro.loc[sfc_hatpro[\"rain\"]==0,vband_all], sfc_hatpro[[\"Tsfc\", \"p\"]]], axis=1, join=\"inner\")\n",
    "TBkqp_hatpro = pd.concat([TB_hatpro.loc[sfc_hatpro[\"rain\"]==0,kband_all], sfc_hatpro[[\"qsfc\", \"p\"]]], axis=1, join=\"inner\")\n",
    "TBvTp_hatpro_nobias = pd.concat([TB_hatpro_nobias.loc[sfc_hatpro[\"rain\"]==0,vband_all], sfc_hatpro[[\"Tsfc\", \"p\"]]], axis=1, join=\"inner\")\n",
    "TBkqp_hatpro_nobias = pd.concat([TB_hatpro_nobias.loc[sfc_hatpro[\"rain\"]==0,kband_all], sfc_hatpro[[\"qsfc\", \"p\"]]], axis=1, join=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also load optest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_optest_bias = read_csv_profiles(\"../data/unified/retrievals/convergence_optest_biased_raso.csv\")\n",
    "x_optest_bias = read_csv_profiles(\"../data/unified/retrievals/x_optest_biased_raso.csv\")\n",
    "T_optest_bias, q_optest_bias = split_x(x_optest_bias)\n",
    "\n",
    "conv_optest = read_csv_profiles(\"../data/unified/retrievals/convergence_optest_raso.csv\")\n",
    "x_optest = read_csv_profiles(\"../data/unified/retrievals/x_optest_raso.csv\")\n",
    "T_optest, q_optest = split_x(x_optest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_optest.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_optest_bias.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regT_all = Model(TBvTp_train, T_train, alpha=500)\n",
    "regq_all = Model(TBkqp_train, q_train, alpha=500)\n",
    "\n",
    "fig, (axT1, axT2, axq1, axq2) = retrieval_template([8, 7],\n",
    "        Tlims=[(-1.2, 4), (0, 12), (-1.1, 1.4), (0, 2.5)],\n",
    "        qlims=[(-0.25, 1.35), (0, 12), (-0.1, 1.35), (0, 2.5)],                                                  \n",
    "        )\n",
    "\n",
    "for ax in [axT1, axT2]:\n",
    "    statistical_eval(ax, T_test,\n",
    "         regT_all(TBvTp_hatpro_nobias),\n",
    "         T_optest_bias.loc[conv_optest_bias[\"converged\"] == 1,:],\n",
    "         T_optest.loc[conv_optest[\"converged\"] == 1,:],\n",
    "         #regT_all(TBvTp_hatpro), # biased regression\n",
    "         #regT_all(TBvTp_test.ix[TBvTp_hatpro.index,:]), # synthetic performance\n",
    "         labels=[\"regression\", \"optimal estimation (biased)\", \"optimal estimation\"],\n",
    "         colors=[\"#33a02c\", \"#666666\", \"#1f78b4\"])\n",
    "    \n",
    "for ax in [axq1, axq2]:\n",
    "    statistical_eval(ax, q_test*1000,\n",
    "         regq_all(TBkqp_hatpro_nobias)*1000,\n",
    "         q_optest_bias.loc[conv_optest_bias[\"converged\"] == 1,:]*1000,\n",
    "         q_optest.loc[conv_optest[\"converged\"] == 1,:]*1000,\n",
    "         #regq_all(TBkqp_hatpro)*1000,\n",
    "         #regq_all(TBkqp_test.ix[TBkqp_hatpro.index,:])*1000,\n",
    "         labels=[\"regression\", \"optimal estimation (biased)\", \"optimal estimation\"],\n",
    "         colors=[\"#33a02c\", \"#666666\", \"#1f78b4\"])\n",
    "    ax.set_ylabel(\"\")\n",
    "    \n",
    "axT1.set_title(\"statistical retrieval evaluation\", loc=\"left\", size=11)\n",
    "axq1.set_title(\"bias (dashed) and std (solid)\", loc=\"right\", size=11)\n",
    "axq1.legend(loc=\"upper right\", fontsize=11)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../tex/figures/retrieval_hatpro.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Continuous Retrieval Experiment\n",
    "\n",
    "A case study showing off the boundary layer evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = read_csv_profiles(\"../data/unified/retrievals/x_optest_continuous.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TBs = read_csv_profiles(\"../data/unified/test/TB_hatpro.csv\").ix[x.index,:].dropna()\n",
    "sfc = read_csv_profiles(\"../data/unified/test/sfc_hatpro.csv\").ix[x.index,:].dropna()\n",
    "sfc.columns = [x if x not in [\"T\", \"qvap\"] else x.replace(\"vap\", \"\")+\"sfc\" for x in sfc.columns]\n",
    "\n",
    "TBvTp_hatpro_nobias = pd.concat([TBs[vband_all], sfc[[\"Tsfc\", \"p\"]]], axis=1, join=\"inner\")\n",
    "regT = Model(TBvTp_train, T_train, alpha=500)\n",
    "\n",
    "Treg = regT(TBvTp_hatpro_nobias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs = GridSpec(1, 3, width_ratios=[10, 10, 0.5])\n",
    "\n",
    "fig = plt.figure(figsize=[8, 4.5])\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "ax2 = fig.add_subplot(gs[1])\n",
    "ax3 = fig.add_subplot(gs[2])\n",
    "\n",
    "VMIN = 293\n",
    "VMAX = 275\n",
    "STEPS = 6\n",
    "intervals = np.linspace(VMAX, VMIN, num=STEPS+1)\n",
    "\n",
    "cmap = plt.get_cmap(\"PuBuGn\", STEPS)\n",
    "norm = plt.Normalize(vmin=VMIN, vmax=VMAX)\n",
    "clrbar = ColorbarBase(ax3, cmap=cmap, norm=norm, orientation=\"vertical\", drawedges=True, extend=\"both\")\n",
    "clrbar.set_label(\"temperature [K]\")\n",
    "clrbar.set_ticks([275, 278, 281, 284, 287, 290, 293])\n",
    "\n",
    "ax1.contourf(range(len(Treg.index)), (rgrid[:23]-612)/1000, Treg.iloc[:,:23].values.T, levels=intervals, cmap=cmap, norm=norm)\n",
    "ax2.contourf(range(len(x.index)-2), (rgrid[:23]-612)/1000, x.iloc[1:-1,:23].values.T, levels=intervals, cmap=cmap, norm=norm)\n",
    "\n",
    "ax1.set_title(\"regression retrieval\", loc=\"left\", fontsize=11)\n",
    "ax2.set_title(\"optimal estimation retrieval\", loc=\"left\", fontsize=11)\n",
    "ax1.set_ylabel(\"height above ground [km]\")\n",
    "ax2.set_yticklabels([])\n",
    "\n",
    "for ax in [ax1, ax2]:\n",
    "    xx = [10, 40, 70, 100, 130]\n",
    "    ax.set_xticks(xx)\n",
    "    ax.set_xticklabels(x.index.strftime(\"%H:%M\")[xx])\n",
    "    ax.set_xlabel(\"time [UTC]\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../tex/figures/retrieval_continuous.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(x.iloc[-2,:23].values, rgrid[:23]-612)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
