{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior Distribution Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "from db_tools import read_csv_covariance, read_csv_profiles\n",
    "from optimal_estimation import rgrid\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COSMO7\n",
    "\n",
    "- Interpolate to radiosonde launch time\n",
    "- Remove bias wrt to radiosonde\n",
    "- Save bias-corrected values and covariance matrix of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interpolate(target, dfs, hourbounds=(0, 6)):\n",
    "    lower = min(min(df.index) for df in dfs)\n",
    "    upper = max(max(df.index) for df in dfs)\n",
    "    idx = pd.Index([\n",
    "            d for d in target.index\n",
    "                    if lower <= d <= upper\n",
    "                    and hourbounds[0] <= d.hour <= hourbounds[1]\n",
    "            ], name=\"valid\")\n",
    "    out = pd.DataFrame(index=idx.union_many(df.index for df in dfs), columns=target.columns, dtype=float)\n",
    "    for df in dfs:\n",
    "        out.ix[df.index] = df\n",
    "    return idx, out.interpolate(method=\"time\", axis=0).ix[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosmo_prior(raso, dfl, dfh):\n",
    "    idx, itp = interpolate(raso, [dfl, dfh])\n",
    "    diff = raso.ix[idx] - itp\n",
    "    return itp + diff.mean(), diff.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Traso = read_csv_profiles(\"../data/unified/T_raso.csv\")\n",
    "Tcosmo00 = read_csv_profiles(\"../data/unified/T_cosmo7+00.csv\")\n",
    "Tcosmo06 = read_csv_profiles(\"../data/unified/T_cosmo7+06.csv\")\n",
    "Tcosmo24 = read_csv_profiles(\"../data/unified/T_cosmo7+24.csv\")\n",
    "Tcosmo30 = read_csv_profiles(\"../data/unified/T_cosmo7+30.csv\")\n",
    "\n",
    "means0006, cov0006 = cosmo_prior(Traso, Tcosmo00, Tcosmo06)\n",
    "means2430, cov2430 = cosmo_prior(Traso, Tcosmo24, Tcosmo30)\n",
    "\n",
    "means0006.to_csv(\"../data/unified/priors/T_cosmo7+00+06_mean.csv\")\n",
    "means2430.to_csv(\"../data/unified/priors/T_cosmo7+24+30_mean.csv\")\n",
    "cov0006.to_csv(\"../data/unified/priors/T_cosmo7+00+06_cov.csv\")\n",
    "cov2430.to_csv(\"../data/unified/priors/T_cosmo7+24+30_cov.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Humidity Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qraso = read_csv_profiles(\"../data/unified/qvap_raso.csv\")\n",
    "qcosmo00 = read_csv_profiles(\"../data/unified/qvap_cosmo7+00.csv\")\n",
    "qcosmo06 = read_csv_profiles(\"../data/unified/qvap_cosmo7+06.csv\")\n",
    "qcosmo24 = read_csv_profiles(\"../data/unified/qvap_cosmo7+24.csv\")\n",
    "qcosmo30 = read_csv_profiles(\"../data/unified/qvap_cosmo7+30.csv\")\n",
    "\n",
    "qraso += read_csv_profiles(\"../data/unified/qliq_raso.csv\")\n",
    "qcosmo00 += read_csv_profiles(\"../data/unified/qliq_cosmo7+00.csv\")\n",
    "qcosmo06 += read_csv_profiles(\"../data/unified/qliq_cosmo7+06.csv\")\n",
    "qcosmo24 += read_csv_profiles(\"../data/unified/qliq_cosmo7+24.csv\")\n",
    "qcosmo30 += read_csv_profiles(\"../data/unified/qliq_cosmo7+30.csv\")\n",
    "\n",
    "means0006, cov0006 = cosmo_prior(np.log(qraso), np.log(qcosmo00), np.log(qcosmo06))\n",
    "means2430, cov2430 = cosmo_prior(np.log(qraso), np.log(qcosmo24), np.log(qcosmo30))\n",
    "\n",
    "means0006.to_csv(\"../data/unified/priors/lnq_cosmo7+00+06_mean.csv\")\n",
    "means2430.to_csv(\"../data/unified/priors/lnq_cosmo7+24+30_mean.csv\")\n",
    "cov0006.to_csv(\"../data/unified/priors/lnq_cosmo7+00+06_cov.csv\")\n",
    "cov2430.to_csv(\"../data/unified/priors/lnq_cosmo7+24+30_cov.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Vector Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xraso = pd.concat([Traso.add_prefix(\"T_\"), np.log(qraso).add_prefix(\"lnq_\")], axis=1)\n",
    "xcosmo00 = pd.concat([Tcosmo00.add_prefix(\"T_\"), np.log(qcosmo00).add_prefix(\"lnq_\")], axis=1)\n",
    "xcosmo06 = pd.concat([Tcosmo06.add_prefix(\"T_\"), np.log(qcosmo06).add_prefix(\"lnq_\")], axis=1)\n",
    "xcosmo24 = pd.concat([Tcosmo24.add_prefix(\"T_\"), np.log(qcosmo24).add_prefix(\"lnq_\")], axis=1)\n",
    "xcosmo30 = pd.concat([Tcosmo30.add_prefix(\"T_\"), np.log(qcosmo30).add_prefix(\"lnq_\")], axis=1)\n",
    "\n",
    "means0006, cov0006 = cosmo_prior(xraso, xcosmo00, xcosmo06)\n",
    "means2430, cov2430 = cosmo_prior(xraso, xcosmo24, xcosmo30)\n",
    "\n",
    "means0006.to_csv(\"../data/unified/priors/x_cosmo7+00+06_mean.csv\")\n",
    "means2430.to_csv(\"../data/unified/priors/x_cosmo7+24+30_mean.csv\")\n",
    "cov0006.to_csv(\"../data/unified/priors/x_cosmo7+00+06_cov.csv\")\n",
    "cov2430.to_csv(\"../data/unified/priors/x_cosmo7+24+30_cov.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Radiosonde Climatology\n",
    "\n",
    "First, separate test and training data. Climatology prior is then only computed from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intestdata(d):\n",
    "    return dt.datetime(2015, 2, 1) < d < dt.datetime(2016, 1, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Traso = read_csv_profiles(\"../data/unified/T_raso.csv\")\n",
    "Tclim = Traso.ix[[v for v in Traso.index if not intestdata(v)]]\n",
    "Ttest = Traso.ix[[v for v in Traso.index if intestdata(v)]]\n",
    "Tclim.to_csv(\"../data/unified/training/T_rasoclim.csv\")\n",
    "Ttest.to_csv(\"../data/unified/test/T_rasoclim.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(Tclim.mean(), columns=[\"T\"]).to_csv(\"../data/unified/priors/T_rasoclim_mean.csv\")\n",
    "Tclim.cov().to_csv(\"../data/unified/priors/T_rasoclim_cov.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qraso = read_csv_profiles(\"../data/unified/qvap_raso.csv\")\n",
    "qraso += read_csv_profiles(\"../data/unified/qliq_raso.csv\")\n",
    "qraso = np.log(qraso)\n",
    "qclim = qraso.ix[[v for v in qraso.index if not intestdata(v)]]\n",
    "qtest = qraso.ix[[v for v in qraso.index if intestdata(v)]]\n",
    "qclim.to_csv(\"../data/unified/training/lnq_rasoclim.csv\")\n",
    "qtest.to_csv(\"../data/unified/test/lnq_rasoclim.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(qclim.mean(), columns=[\"lnq\"]).to_csv(\"../data/unified/priors/lnq_rasoclim_mean.csv\")\n",
    "qclim.cov().to_csv(\"../data/unified/priors/lnq_rasoclim_cov.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xclim = pd.concat([Traso.add_prefix(\"T_\"), qraso.add_prefix(\"lnq_\")], axis=1)\n",
    "pd.DataFrame(xclim.mean(), columns=[\"x\"]).to_csv(\"../data/unified/priors/x_rasoclim_mean.csv\")\n",
    "xclim.cov().to_csv(\"../data/unified/priors/x_rasoclim_cov.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloudy cases\n",
    "\n",
    "Mark cloudy profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raso = read_csv_profiles(\"../data/unified/qliq_raso.csv\")\n",
    "clim = raso.ix[[v for v in raso.index if not intestdata(v)]]\n",
    "test = raso.ix[[v for v in raso.index if intestdata(v)]]\n",
    "(clim.sum(axis=1) > 0).rename(\"cloudy\").to_frame().to_csv(\"../data/unified/training/cloudy_raso.csv\")\n",
    "(test.sum(axis=1) > 0).rename(\"cloudy\").to_frame().to_csv(\"../data/unified/test/cloudy_raso.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "igmk = read_csv_profiles(\"../data/unified/cloudy_igmk.csv\")\n",
    "igmk = igmk.reindex(clim.index, method=\"nearest\", tolerance=dt.timedelta(minutes=60)).dropna()\n",
    "igmk = igmk.drop(dt.datetime(1999, 11, 18, 22, 51)) # foreshadowing...\n",
    "igmk = igmk.drop(dt.datetime(2012, 2, 14, 3, 37)) # foreshadowing...\n",
    "igmk.ix[[v for v in raso.index if not intestdata(v)]].dropna().to_csv(\"../data/unified/training/cloudy_igmk.csv\")\n",
    "# no test set b/c no data in period available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Radiative Transfer Model\n",
    "\n",
    "Separate training and test datasets. Then use only clear-sky cases for determination of covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mwrtm = read_csv_profiles(\"../data/unified/TB_mwrtm_6000_full_hr.csv\").drop([\"T\", \"qvap\"], axis=1)\n",
    "mwrtm_train = mwrtm.drop(\"p\", axis=1).ix[[v for v in mwrtm.index if not intestdata(v)]]\n",
    "mwrtm_test = mwrtm.drop(\"p\", axis=1).ix[[v for v in mwrtm.index if intestdata(v)]]\n",
    "mwrtm_train.to_csv(\"../data/unified/training/TB_mwrtm.csv\")\n",
    "mwrtm_test.to_csv(\"../data/unified/test/TB_mwrtm.csv\")\n",
    "\n",
    "psfc = mwrtm[[\"p\"]]\n",
    "psfc.ix[[v for v in psfc.index if not intestdata(v)]].to_csv(\"../data/unified/training/psfc.csv\")\n",
    "psfc.ix[[v for v in psfc.index if intestdata(v)]].to_csv(\"../data/unified/test/psfc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_tb_data(filename):\n",
    "    df = read_csv_profiles(filename).drop([\"p\", \"T\", \"qvap\"], axis=1)\n",
    "    train = df.ix[[v for v in df.index if not intestdata(v)]]\n",
    "    test = df.ix[[v for v in df.index if intestdata(v)]]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mwrtmfap_train, mwrtmfap_test = load_tb_data(\"../data/unified/TB_mwrtm_2500_fap.csv\")\n",
    "mwrtmfap_train.to_csv(\"../data/unified/training/TB_mwrtm_fap.csv\")\n",
    "mwrtmfap_test.to_csv(\"../data/unified/test/TB_mwrtm_fap.csv\")\n",
    "\n",
    "monortm_train, monortm_test = load_tb_data(\"../data/unified/TB_monortm_hr.csv\")\n",
    "monortm_train.to_csv(\"../data/unified/training/TB_monortm.csv\")\n",
    "monortm_test.to_csv(\"../data/unified/test/TB_monortm.csv\")\n",
    "\n",
    "igmk_train, igmk_test = load_tb_data(\"../data/unified/TB_igmk.csv\")\n",
    "igmk_train = igmk_train.reindex(mwrtm_train.index, method=\"nearest\", tolerance=dt.timedelta(minutes=60)).dropna()\n",
    "igmk_train = igmk_train.drop(dt.datetime(2012, 2, 14, 3, 37)) # foreshadowing...\n",
    "igmk_train.to_csv(\"../data/unified/training/TB_igmk.csv\")\n",
    "# no test set b/c no data in period available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cloudy_raso = read_csv_profiles(\"../data/unified/training/cloudy_raso.csv\")[\"cloudy\"]\n",
    "cloudy_igmk = read_csv_profiles(\"../data/unified/training/cloudy_igmk.csv\")[\"cloudy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine all kinds of covariance matrices for clear-skies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cov = (mwrtmfap_train.loc[~cloudy_raso,monortm_train.columns] - monortm_train.loc[~cloudy_raso,:]).dropna(axis=0).cov()\n",
    "cov.to_csv(\"../data/unified/priors/TB_mwrtm_fap_monortm_cov.csv\")\n",
    "\n",
    "cov = (mwrtmfap_train.loc[~cloudy_raso,:] - igmk_train.ix[cloudy_igmk.index][~cloudy_igmk]).dropna(axis=0).cov()\n",
    "cov.to_csv(\"../data/unified/priors/TB_mwrtm_fap_igmk_cov.csv\")\n",
    "\n",
    "cov = (igmk_train.ix[cloudy_igmk.index][~cloudy_igmk][monortm_train.columns] - monortm_train[~cloudy_raso]).dropna(axis=0).cov()\n",
    "cov.to_csv(\"../data/unified/priors/TB_igmk_monortm_cov.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MWRTM - HATPRO bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbs = read_csv_profiles(\"../data/unified/test/TB_hatpro.csv\")\n",
    "tb_mwrtm = read_csv_profiles(\"../data/unified/test/TB_mwrtm.csv\")\n",
    "tb_mwrtmfap = read_csv_profiles(\"../data/unified/test/TB_mwrtm_fap.csv\")\n",
    "tb_monortm = read_csv_profiles(\"../data/unified/test/TB_monortm.csv\")\n",
    "cloudy = read_csv_profiles(\"../data/unified/test/cloudy_raso.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tb_hatpro = tbs.reindex(tb_mwrtm.index, method=\"nearest\", tolerance=dt.timedelta(minutes=30)).dropna()\n",
    "tb_hatpro = pd.concat([tb_hatpro, cloudy], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the large uncertainties with cloud representation in the radiosonde ascents, only clear sky observations are considered for the bias calculation.\n",
    "\n",
    "The observation from 2015-10-29 02:15:06 is classified as clear from the radiosonde but the webcam picture clearly\n",
    "shows the existence of a liquid cloud layer:\n",
    "\n",
    "<img src=\"http://www.foto-webcam.eu/webcam/innsbruck/2015/10/29/0420_la.jpg\" width=50%>\n",
    "\n",
    "It is therefore removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tb_hatpro = tb_hatpro.where(~tb_hatpro[\"cloudy\"]).dropna().iloc[:-1,:]\n",
    "len(tb_hatpro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is poor statistics but what else to do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(tb_mwrtm - tb_hatpro).mean().dropna().rename(\"bias\").to_frame().to_csv(\"../data/unified/priors/TB_mwrtm_bias.csv\")\n",
    "(tb_mwrtmfap - tb_hatpro).mean().dropna().rename(\"bias\").to_frame().to_csv(\"../data/unified/priors/TB_mwrtm_fap_bias.csv\")\n",
    "(tb_monortm - tb_hatpro).mean().dropna().rename(\"bias\").to_frame().to_csv(\"../data/unified/priors/TB_monortm_bias.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias must be subtracted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
